{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Custom imports\n",
    "from model.utils import *\n",
    "from model.data_utils import *\n",
    "from model.transformer import Transformer\n",
    "from model.bracketing import IdentityChunker, NNSimilarityChunker, cos\n",
    "from model.generators import IdentityGenerator, EmbeddingGenerator\n",
    "from model.classifiers import AttentionClassifier, SeqPairAttentionClassifier\n",
    "from model.model import MultiTaskNet, End2EndModel\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Model Options')\n",
    "#parser.add_argument('integers', metavar='N', type=int, nargs='+',\n",
    "#                    help='an integer for the accumulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
      "/Users/sergicastellasape/miniconda3/envs/za_conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# LOAD SST-2\n",
    "DATA_SST_TRAIN = pd.read_csv('./assets/datasets/SST2/SST2_dataset_train.csv', sep='\\t')\n",
    "DATA_SST_TEST = pd.read_csv('./assets/datasets/SST2/SST2_dataset_test.csv', sep='\\t')\n",
    "DATA_SST_DEV = pd.read_csv('./assets/datasets/SST2/SST2_dataset_dev.csv', sep='\\t')\n",
    "\n",
    "# LOAD QUORA QUESTION PAIRS\n",
    "DATA_QQP_TRAIN = pd.read_csv('./assets/datasets/QQP/QQP_train.tsv', sep='\\t', error_bad_lines=False)\n",
    "DATA_QQP_TEST = pd.read_csv('./assets/datasets/QQP/QQP_test.tsv', sep='\\t', error_bad_lines=False)\n",
    "DATA_QQP_DEV = pd.read_csv('./assets/datasets/QQP/QQP_dev.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device being used: {device}\")\n",
    "\n",
    "\n",
    "########### LOAD MODELS AND OPTIMIZER ###########\n",
    "transformer_net = Transformer(model_class=BertModel,\n",
    "                              tokenizer_class=BertTokenizer,\n",
    "                              pre_trained_weights='bert-base-uncased',\n",
    "                              device=device)\n",
    "\n",
    "bracketing_net = NNSimilarityChunker(sim_function=cos,\n",
    "                                     threshold=3,\n",
    "                                     exclude_special_tokens=False,\n",
    "                                     combinatorics='sequential',\n",
    "                                     device=device)\n",
    "bracketing_net = IdentityChunker()\n",
    "generator_net = IdentityGenerator()\n",
    "#generator_net = EmbeddingGenerator(pool_function=abs_max_pooling, \n",
    "#                                   device=device)\n",
    "\n",
    "seq_classifier = AttentionClassifier(embedding_dim=768,\n",
    "                                       sentset_size=2,\n",
    "                                       batch_size=32,\n",
    "                                       dropout=0.3,\n",
    "                                       n_sentiments=4,\n",
    "                                       pool_mode='concat',\n",
    "                                       device=device)\n",
    "\n",
    "\n",
    "seq_pair_classifier = SeqPairAttentionClassifier(embedding_dim=768,\n",
    "                                              num_classes=4,\n",
    "                                              batch_size=32,\n",
    "                                              dropout=0.3,\n",
    "                                              n_attention_vecs=4,\n",
    "                                              pool_mode='concat',\n",
    "                                              device=device)\n",
    "\n",
    "multitask_net = MultiTaskNet(seq_classifier, \n",
    "                             device=device)\n",
    "\n",
    "model = End2EndModel(transformer=transformer_net,\n",
    "                     bracketer=bracketing_net,\n",
    "                     generator=generator_net,\n",
    "                     multitasknet=multitask_net,\n",
    "                     device=device)\n",
    "\n",
    "batch_sequence = ['this is one sentence', 'this is a second sentence', 'this is a third sentnen.']\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.Adam(multitask_net.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.7339, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6660, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7073, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7109, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7285, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7117, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6981, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7257, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6321, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7096, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6522, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7007, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6977, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6777, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7365, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7190, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6960, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6877, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7009, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7102, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7320, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7035, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6791, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7247, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7187, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6624, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6530, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7184, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7049, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6916, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7584, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7115, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6913, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6944, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6626, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7106, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7526, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7166, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6758, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7265, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6936, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6940, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7029, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7565, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6474, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7238, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7194, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7618, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7297, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7009, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6798, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7097, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7287, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6360, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7064, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6935, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7115, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6962, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7116, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6976, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7214, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7178, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7290, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6992, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7239, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6336, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7270, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6925, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7527, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6678, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6998, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6957, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7270, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6828, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6592, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6372, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7161, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7172, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7220, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7211, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7247, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6661, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7013, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7255, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7126, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6876, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7318, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6813, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7133, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6948, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6351, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6953, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7181, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6643, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7138, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7357, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7535, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6984, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7179, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6783, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7347, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6617, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6665, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7167, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6941, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7092, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7554, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6245, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6946, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6960, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6654, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7059, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6460, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6876, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7014, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6908, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6977, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7048, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6617, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6961, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7114, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7335, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7237, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7021, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7280, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6658, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6750, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6908, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6811, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6785, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6491, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6290, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6638, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7254, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6954, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6648, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7167, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6640, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7083, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7017, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7001, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7178, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7129, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6953, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.7585, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6586, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7267, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7584, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7179, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7160, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7656, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6997, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6587, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7166, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6386, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6742, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7171, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7171, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7212, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6909, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6891, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7185, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6556, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7522, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7000, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7206, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6875, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7044, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7072, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7134, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6643, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6592, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6639, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7025, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7548, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6636, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6305, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6649, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6294, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6774, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6597, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6879, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6620, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7285, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6984, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6928, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7516, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7261, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6869, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7323, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7494, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7312, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6329, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6982, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6858, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6622, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7217, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6945, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7256, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6901, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6811, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6677, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6670, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6623, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6907, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6910, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7411, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7517, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6594, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7246, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7020, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7010, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7523, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6641, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7322, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6387, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7171, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7022, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6938, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6971, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6951, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7202, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7419, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6944, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6968, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6625, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6933, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6914, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7417, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6930, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7208, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7248, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6983, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7413, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6828, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6985, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6938, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6626, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6905, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7230, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6751, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7015, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6928, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7173, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6916, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6790, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6281, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6954, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6590, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6918, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6942, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7235, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6769, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6627, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7163, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6790, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6866, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7055, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6585, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6631, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7125, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7179, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7073, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7185, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6405, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7263, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7064, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6375, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6582, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7047, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6655, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6606, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7566, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6957, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7011, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6563, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6943, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6635, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7261, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6365, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6991, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6509, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7283, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7297, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7294, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6950, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6939, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6924, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7550, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7224, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7166, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7470, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.7184, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6829, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6627, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7525, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6610, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6983, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7184, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7497, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6833, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6383, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7190, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6511, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6981, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6556, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7072, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7269, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7348, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6497, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7162, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7112, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6815, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6970, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6599, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6809, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7199, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6542, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6885, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7256, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6891, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7213, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6935, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7191, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7272, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6946, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6981, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6834, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7162, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7282, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6887, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6592, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7154, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7230, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6613, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7279, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7240, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6671, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6987, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6570, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6575, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6422, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7184, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7369, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6962, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6988, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6902, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7050, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7009, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6901, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6501, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6968, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6673, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6966, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6697, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7286, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6869, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7116, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7106, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6961, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6974, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7410, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7141, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6283, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6881, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6762, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7727, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7157, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7321, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7288, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7624, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7207, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7207, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6941, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7188, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6904, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6943, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6768, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7180, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6972, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6762, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7018, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6663, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6511, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6980, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6463, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7052, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6808, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7208, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7136, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6873, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6810, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6636, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6955, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6326, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6578, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6955, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6779, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6640, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7090, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7254, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7003, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7069, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6972, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6604, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6608, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7148, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6872, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7294, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6905, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7024, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6601, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7229, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6957, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7322, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6971, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7050, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7192, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6831, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6376, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6796, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6806, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6968, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7278, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7154, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7071, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6360, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6958, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7156, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7110, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7645, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6610, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6930, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7200, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6985, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6937, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7186, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7175, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6631, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6347, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7206, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6475, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.6928, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6923, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7001, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6830, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7245, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7208, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7295, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7253, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6528, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7300, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6355, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7004, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6905, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7131, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6379, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7198, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6480, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6423, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7231, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6575, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6999, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7128, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7523, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7020, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6694, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6629, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7102, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7165, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7224, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6992, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7295, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6507, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6604, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6457, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6822, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6262, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7184, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7194, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7195, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6980, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6967, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6919, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7066, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6889, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7113, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7347, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7424, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7107, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6639, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6540, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7317, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7107, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6533, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6546, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7180, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7012, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6884, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6768, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6802, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7307, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7190, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7222, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6600, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7693, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7314, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7208, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6967, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6481, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6909, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7212, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6920, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6866, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6990, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6534, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7286, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7569, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7010, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6836, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6986, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6965, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6889, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6732, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6802, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6976, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7691, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6892, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7274, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7100, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7200, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7358, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6999, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6655, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7182, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6292, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7271, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7340, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7102, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6816, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6969, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7146, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6805, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7069, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7656, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6908, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7245, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6768, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7277, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7028, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6246, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7016, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6613, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7574, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7116, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6755, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7237, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6635, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7317, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7220, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6919, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6621, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7557, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6764, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6761, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7299, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7075, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6814, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6781, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7152, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6951, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7008, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7359, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7268, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7057, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7131, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6423, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.6532, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6913, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7132, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6875, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7188, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6564, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7407, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7366, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6909, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6696, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7321, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6825, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7227, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6663, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6931, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6825, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6923, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7370, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6754, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7652, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6887, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7058, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7070, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7270, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6790, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6962, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7255, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6670, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6962, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7007, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7098, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7168, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7516, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7000, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6512, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7009, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7029, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6915, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6969, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7573, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6590, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7021, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6929, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7219, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6991, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7318, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6221, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6946, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7236, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6867, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7010, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6965, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6661, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6516, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7201, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6756, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6951, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6977, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7064, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7048, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6936, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6606, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6801, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7058, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6666, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6662, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7218, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6973, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7763, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7275, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7141, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6801, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6900, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6794, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6545, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6940, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6640, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7036, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6976, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6573, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7295, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7281, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6580, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6611, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6995, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7039, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7557, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7018, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6972, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6502, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6976, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7217, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6912, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7057, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7178, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7032, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7515, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6808, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6615, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6898, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7004, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7010, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6633, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7048, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7111, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7280, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7262, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6973, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7062, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6638, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7367, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7167, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7218, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6694, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6968, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7363, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6915, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6757, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7577, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6991, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7341, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7545, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6929, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6798, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6701, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7178, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7509, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7018, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6817, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7507, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7563, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6446, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7021, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6954, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7495, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7499, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6975, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6908, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.6378, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6595, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7195, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7185, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6956, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6673, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7149, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6566, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6921, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7261, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7189, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6585, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7288, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7240, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6508, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7013, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7227, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7090, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6886, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6810, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6960, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6481, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6416, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7143, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6987, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6558, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7186, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6433, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6893, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7100, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7137, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6647, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7200, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7018, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7257, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6987, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6924, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6982, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6687, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6499, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7229, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6962, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6951, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6606, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7687, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7322, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7041, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6550, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6925, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6853, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6952, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7305, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7276, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7555, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6891, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6919, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7150, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6344, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6950, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7020, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7337, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7259, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6813, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7342, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7185, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6171, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6626, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6912, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6416, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6966, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6998, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6632, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6617, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7028, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6496, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6760, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7328, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6615, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7568, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6916, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6967, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7573, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6941, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7319, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7026, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7133, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7506, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6969, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7254, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6667, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7079, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6911, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6897, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7179, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7166, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6657, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6930, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7307, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6758, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7591, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7276, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7213, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6968, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7253, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7126, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7562, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6602, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7287, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7309, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7154, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7319, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6924, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6638, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7231, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7084, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6925, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7147, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7254, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7593, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7003, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6903, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6257, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6975, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7038, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7236, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6374, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6967, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6804, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7472, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6935, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7098, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7073, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6244, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6941, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7021, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6599, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7346, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6904, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6751, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7120, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6647, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7167, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6359, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7245, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6285, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6934, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7120, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7100, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7053, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6894, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7165, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7288, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6910, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6669, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7220, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6995, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7323, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7006, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7163, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7063, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6829, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6788, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7310, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6988, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.6594, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7140, grad_fn=<MeanBackward0>)\n",
      "Loss:  tensor(0.7028, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model.data_utils import get_batch_SST2_from_indices, get_batch_QQP_from_indices\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\"\"\"\n",
    "batch_size = {'SST2': 4, 'QQP': 4}\n",
    "n_batches = {'SST2': 10, 'QQP': 10}\n",
    "counter = {'SST2': 0, 'QQP': 0}\n",
    "get_batch_function = {'SST2': get_batch_SST2_from_indices, 'QQP': get_batch_QQP_from_indices}\n",
    "dataframe = {'SST2': DATA_SST_TRAIN, 'QQP': DATA_QQP_TRAIN}\n",
    "\n",
    "datasets = ['SST2', 'QQP']\n",
    "batch_indices = {}\n",
    "\"\"\"\n",
    "\n",
    "batch_size = {'SST2': 4, 'QQP': 4}\n",
    "n_batches = {'SST2': 10, 'QQP': 10}\n",
    "counter = {'SST2': 0, 'QQP': 0}\n",
    "get_batch_function = {'SST2': get_batch_SST2_from_indices, 'QQP': get_batch_QQP_from_indices}\n",
    "dataframe = {'SST2': DATA_SST_TRAIN, 'QQP': DATA_QQP_TRAIN}\n",
    "\n",
    "datasets = ['SST2']\n",
    "batch_indices = {}\n",
    "\n",
    "optimizer = torch.optim.Adam(multitask_net.parameters(), \n",
    "                             lr=0.01, \n",
    "                             betas=(0.9, 0.999), \n",
    "                             eps=1e-08, \n",
    "                             weight_decay=0.01, \n",
    "                             amsgrad=False)\n",
    "\n",
    "global_counter = 0\n",
    "finished_training = False\n",
    "\n",
    "while not finished_training:\n",
    "    for dataset in datasets:\n",
    "        if counter[dataset] > n_batches[dataset] or global_counter == 0:\n",
    "            counter[dataset] = 0\n",
    "            # Re-shuffle the training batches data\n",
    "            batch_indices[dataset] = torch.randperm(n_batches[dataset]*batch_size[dataset],\n",
    "                                                    device=device).reshape(-1, batch_size[dataset])\n",
    "    \n",
    "    batch_sequences, batch_targets, batch_splits = [], [], [0]\n",
    "    for dataset in datasets:\n",
    "        idx = counter[dataset]\n",
    "        dataset_batch = get_batch_function[dataset](dataframe[dataset], \n",
    "                                                    batch_indices[dataset][idx])\n",
    "\n",
    "        # List of tensors, one for each task\n",
    "        batch_targets.append(torch.tensor([data[1] for data in dataset_batch], \n",
    "                                          dtype=torch.int64, \n",
    "                                          device=device))\n",
    "        \n",
    "        # Big list combining the input sequences/ tuple of sequences because the batch needs\n",
    "        # to be at the same \"depth\" level\n",
    "        batch_sequences.extend([data[0] for data in dataset_batch])\n",
    "        batch_splits.append(batch_splits[-1] + len(dataset_batch))\n",
    "        counter[dataset] += 1\n",
    "\n",
    "    model.train()\n",
    "    batch_predictions = model.forward(batch_sequences, batch_splits=batch_splits)\n",
    "    L = model.loss(batch_predictions, batch_targets, weights = None)\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    print('Loss: ', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_sequence_pairs = [('Why Tamil Nadu Universities are no good ?  lol this is longer.', 'What was the deadliest battle in history?'),\n",
    "                       ('What are the difference between polyester','What is the difference between cotton and poly'),\n",
    "                       ('What are the difference between polyester', 'What was the deadliest battle in history?')]\n",
    "batch_sequence = ['Why Tamil Nadu Universities are no good?', \n",
    "                  'What was the deadliest battle in history?',\n",
    "                  'What are the difference between polyester']\n",
    "combined = batch_sequence_pairs + batch_sequence\n",
    "output, masks_dict = transformer_net.forward(combined, return_masks=True)\n",
    "print(output.size())\n",
    "print(masks_dict['seq_pair_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [(1, 3),(1, 3),(6, 0)]\n",
    "[l[:-1][:] for l in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ['hola', 'que', 'taas', 'asdf', 'qwe?']\n",
    "L[0:3]\n",
    "L[3:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a, **kwargs):\n",
    "    print('First argument is: ', a)\n",
    "    if second_argument:\n",
    "        print('second argument:', second_argument)\n",
    "        \n",
    "function('hoola', second_argument=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL = [[1, 0, 0, 1], [1, 0], [1, 0, 0, 0, 0, 0, 1]]\n",
    "dict_L = {}\n",
    "dict_L['list'] = LL\n",
    "max_len = max([len(l) for l in dict_L['list']])\n",
    "print(dict_L['list'])\n",
    "dict_L['list'] = [L + [1]*(max_len-len(L)) for L in dict_L['list']]\n",
    "dict_L['list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[True, True, False],[True, False, False]], dtype=torch.bool)\n",
    "T = mask.sum(dim=0) == 0\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor([[4, 2, 3],[5, 2, 3]])\n",
    "print(-T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = torch.tensor([1, 4, 5])\n",
    "T = torch.tensor([[6, 10, 5, 2], \n",
    "                  [1, 1, 1, 1]], dtype=torch.float32)\n",
    "T.prod(dim=1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "T1 = torch.tensor([True, False, False], dtype=torch.bool)\n",
    "T2 = torch.tensor([True, True, False], dtype=torch.bool)\n",
    "T1 * T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([True, False, True, True], dtype=torch.bool)\n",
    "T = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "T[:, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "indices = [0, 1, 2, 3, 4, 5]\n",
    "idx_combinations = [indices[s:e] for s, e in itertools.combinations(range(len(indices)+1), 2)]\n",
    "print(idx_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zeta Alpha",
   "language": "python",
   "name": "za_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
