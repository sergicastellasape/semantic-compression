{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sergicastellasape/Repos/zeta-alpha/semantic-compression'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "from model.transformer import Transformer\n",
    "from model.classifiers import SeqPairAttentionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = './assets/pre-trainings/scibert_basevocab_uncased'\n",
    "TRF = Transformer(model_class=BertModel, tokenizer_class=BertTokenizer, pre_trained_weights='bert-base-uncased')\n",
    "pair_classifier = SeqPairAttentionClassifier(768,\n",
    "                                             5,\n",
    "                                             3,\n",
    "                                             dropout=0., \n",
    "                                             n_attention_vecs=4, \n",
    "                                             pool_mode='concat', \n",
    "                                             device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = ['This is a first sequence, with a coma.', 'The second sequence of the batch. With a point!', 'My grandma turned 96 recently.']\n",
    "batch2 = ['sentence corresponding to first', 'same but to the second.', 'guess what? Same to third one']\n",
    "batch1_context_embeddings = TRF(batch1, output_layer=-3)\n",
    "batch2_context_embeddings = TRF(batch2, output_layer=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score = pair_classifier((batch1_context_embeddings, batch2_context_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    assert type(n) == int\n",
    "    if n > 1:\n",
    "        return n*factorial(n-1)\n",
    "    elif n <= 1:\n",
    "        return n\n",
    "\n",
    "factorial(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "A = np.empty(10, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None None None None None None None None None None]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "inp = torch.tensor([[1, 2, 3], [5, 2, 3]], dtype=torch.float32 ,requires_grad=True)\n",
    "ID = nn.Identity()\n",
    "out = ID.forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [5., 2., 3.]], requires_grad=True)\n",
      "tensor([[1., 2., 3.],\n",
      "        [5., 2., 3.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "original: (5,)\n",
      "list: [5]\n"
     ]
    }
   ],
   "source": [
    "def func(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "    L = list(args)\n",
    "    print('original:', args)\n",
    "    print('list:', L)\n",
    "    \n",
    "func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [2], []]\n"
     ]
    }
   ],
   "source": [
    "L = [[] for _ in range(3)]\n",
    "L[1].append(2)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, 14], [None, 14], [None, 14], [None, 14], [None, 14], [None, 14], [None, 14], [None, 14], [None, 14], [None, 14]]\n"
     ]
    }
   ],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.combinations(range(1, 5), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [1, 2, 3, 4, 5]\n",
    "L[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zeta Alpha",
   "language": "python",
   "name": "za_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
